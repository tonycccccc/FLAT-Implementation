{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b91ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob2\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "321cd5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revise the FlatDataflow function to make it clearer\n",
    "\n",
    "def FlatDataflow(loop_num, query, key, value, bias, batch_granularity_level=1, head_granularity_level=8, length_granularity_level=64, headTrue = False):\n",
    "  if (tf.config.list_physical_devices('CPU')):\n",
    "    # If the dimension of the input tensor is 3 rather than 4, expand its dimension for the batch\n",
    "    if (len(query.shape) == 3):\n",
    "      query = query[None, :, :, :]\n",
    "      key = key[None, :, :, :]\n",
    "      value = value[None, :, :, :]  \n",
    "    batch_size, source_length, head_num, dim = tf.shape(query).numpy()\n",
    "    # Set a fixed bias value here\n",
    "    bias_value = bias\n",
    "    for batch in tf.range(0, batch_size, batch_granularity_level):\n",
    "      # The lowest granularity is batch level.\n",
    "      if (batch_granularity_level != 1):\n",
    "        end_batch = batch + batch_granularity_level if batch + batch_granularity_level1 <= batch_size else batch_size\n",
    "        query_source = tf.gather(query[:, :, :, :], indices=tf.range(batch, end_batch), axis=0)\n",
    "        key_source = tf.gather(key[:, :, :, :], indices=tf.range(batch, end_batch), axis=0)\n",
    "        value_source = tf.gather(value[:, :, :, :], indices=tf.range(batch, end_batch), axis=0)\n",
    "        result = tf.einsum(\"BTNH, BFNH->BNFT\", key_source, query_source)\n",
    "        result += bias_value\n",
    "        result = tf.nn.softmax(result, name=\"attention_weights\")\n",
    "        result = tf.nn.dropout(result, rate=0.4)\n",
    "        attention_output = tf.einsum(\"BNFT,BTNH->BFNH\", result, value_source)\n",
    "      else:\n",
    "        for head in tf.range(0, head_num, head_granularity_level):\n",
    "          # The lowest granularity is head level.\n",
    "          if (head_granularity_level != 1 or headTrue):\n",
    "            end_head = head + head_granularity_level if head + head_granularity_level <= head_num else head_num\n",
    "            query_source = tf.gather(query[batch, :, :, :], indices=tf.range(head, end_head), axis=1)\n",
    "            key_source = tf.gather(key[batch, :, :, :], indices=tf.range(head, end_head), axis=1)\n",
    "            value_source = tf.gather(value[batch, :, :, :], indices=tf.range(head, end_head), axis=1)\n",
    "            result = tf.einsum(\"TNH, FNH->NFT\", key_source, query_source)\n",
    "            result += bias_value\n",
    "            result = tf.nn.softmax(result, name=\"attention_weights\")\n",
    "            result = tf.nn.dropout(result, rate=0.4)\n",
    "            logit = tf.einsum(\"NFT,TNH->FNH\", result, value_source)\n",
    "            if head == 0:\n",
    "              attention_output = logit\n",
    "            else:\n",
    "              attention_output = tf.concat([attention_output, logit], axis=1)\n",
    "          else:\n",
    "            #Lowest granularity is length level\n",
    "            for length in tf.range(0, source_length, length_granularity_level):\n",
    "              end_length = length + length_granularity_level if length + length_granularity_level <= source_length else source_length\n",
    "              query_source = tf.gather(query[batch, :, head, :], indices=tf.range(length, end_length), axis=0)\n",
    "              key_source = key[batch, :, head, :]\n",
    "              result = tf.einsum(\"TH, FH->FT\", key_source, query_source)\n",
    "              result += bias_value\n",
    "              result = tf.nn.softmax(result, name=\"attention_weights\")\n",
    "              result = tf.nn.dropout(result, rate=0.4)\n",
    "              if length == 0:\n",
    "                lengthOutput = result\n",
    "              else:\n",
    "                lengthOutput = tf.concat([lengthOutput, result], axis=0)\n",
    "            value_source = value[batch, :, head, :]\n",
    "            lengthRes = tf.einsum(\"FT,TH->FH\", lengthOutput, value_source)\n",
    "            lengthRes = tf.expand_dims(lengthRes, axis=1)\n",
    "            if (head == 0):\n",
    "              attention_output = lengthRes\n",
    "            else:\n",
    "              attention_output = tf.concat([attention_output, lengthRes], axis=1)\n",
    "        attention_output = tf.expand_dims(attention_output, axis=0)\n",
    "      if (batch == 0):\n",
    "        output = attention_output\n",
    "      else:\n",
    "        output = tf.concat([output, attention_output], axis=0)\n",
    "    stoptime = time.time()\n",
    "    return (0, 0, 0, 0, stoptime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa3ffb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files Successfully Loaded!\n",
      "LOOP 4\n",
      "LOOP 5\n",
      "LOOP 6\n",
      "LOOP 7\n",
      "LOOP 8\n",
      "LOOP 9\n",
      "LOOP 10\n",
      "LOOP 11\n",
      "LOOP 12\n",
      "LOOP 13\n",
      "LOOP 14\n",
      "LOOP 15\n",
      "LOOP 16\n",
      "LOOP 17\n",
      "LOOP 18\n",
      "LOOP 19\n",
      "LOOP 20\n",
      "LOOP 21\n",
      "LOOP 22\n",
      "LOOP 23\n",
      "LOOP 24\n",
      "LOOP 25\n",
      "LOOP 26\n",
      "LOOP 27\n",
      "LOOP 28\n",
      "LOOP 29\n",
      "LOOP 30\n",
      "LOOP 31\n",
      "LOOP 32\n",
      "LOOP 33\n",
      "LOOP 34\n",
      "LOOP 35\n",
      "LOOP 36\n",
      "LOOP 37\n",
      "LOOP 38\n",
      "LOOP 39\n",
      "LOOP 40\n",
      "LOOP 41\n",
      "LOOP 42\n",
      "LOOP 43\n",
      "LOOP 44\n",
      "LOOP 45\n",
      "LOOP 46\n",
      "LOOP 47\n",
      "LOOP 48\n",
      "LOOP 49\n",
      "LOOP 50\n",
      "LOOP 51\n",
      "LOOP 52\n",
      "LOOP 53\n",
      "LOOP 54\n",
      "LOOP 55\n",
      "LOOP 56\n",
      "LOOP 57\n",
      "LOOP 58\n",
      "LOOP 59\n",
      "LOOP 60\n",
      "LOOP 61\n",
      "LOOP 62\n",
      "LOOP 63\n",
      "LOOP 64\n",
      "LOOP 65\n",
      "LOOP 66\n",
      "LOOP 67\n",
      "LOOP 68\n",
      "LOOP 69\n",
      "LOOP 70\n",
      "LOOP 71\n",
      "LOOP 72\n",
      "LOOP 73\n",
      "LOOP 74\n",
      "LOOP 75\n",
      "LOOP 76\n",
      "LOOP 77\n",
      "LOOP 78\n",
      "LOOP 79\n",
      "LOOP 80\n",
      "LOOP 81\n",
      "LOOP 82\n",
      "LOOP 83\n",
      "LOOP 84\n",
      "LOOP 85\n",
      "LOOP 86\n",
      "LOOP 87\n",
      "LOOP 88\n",
      "LOOP 89\n",
      "LOOP 90\n",
      "LOOP 91\n",
      "LOOP 92\n",
      "LOOP 93\n",
      "LOOP 94\n",
      "LOOP 95\n",
      "LOOP 96\n",
      "LOOP 97\n",
      "LOOP 98\n",
      "LOOP 99\n",
      "LOOP 100\n",
      "LOOP 101\n",
      "LOOP 102\n",
      "LOOP 103\n",
      "LOOP 104\n",
      "LOOP 105\n",
      "LOOP 106\n",
      "LOOP 107\n",
      "LOOP 108\n",
      "LOOP 109\n",
      "LOOP 110\n",
      "LOOP 111\n",
      "LOOP 112\n",
      "LOOP 113\n",
      "LOOP 114\n",
      "LOOP 115\n",
      "LOOP 116\n",
      "LOOP 117\n",
      "LOOP 118\n",
      "LOOP 119\n",
      "LOOP 120\n",
      "LOOP 121\n",
      "LOOP 122\n",
      "LOOP 123\n",
      "LOOP 124\n",
      "LOOP 125\n",
      "LOOP 126\n",
      "LOOP 127\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# Code block building graph with x-axis as sequence length and y-axis as peak memory usage\n",
    "\n",
    "# Read in all the files\n",
    "query_file = glob2.glob(\"/Users/zeyuchen/Desktop/FLAT/FILES/logging_query*.txt\")\n",
    "key_file = glob2.glob(\"/Users/zeyuchen/Desktop/FLAT/FILES/logging_key*.txt\")\n",
    "value_file = glob2.glob(\"/Users/zeyuchen/Desktop/FLAT/FILES/logging_value*.txt\")\n",
    "\n",
    "# Randomly set a bias value for now\n",
    "BIAS = 0.02\n",
    "\n",
    "running_time = []\n",
    "\n",
    "FILENUM = len(query_file)\n",
    "BATCHSIZE = 64\n",
    "queryin = []\n",
    "keyin = []\n",
    "valuein = []\n",
    "for file in query_file:\n",
    "    qfile = tf.io.read_file(file)\n",
    "    query = tf.io.parse_tensor(qfile, out_type=tf.float32)\n",
    "    queryin.append(query)\n",
    "for file in key_file:\n",
    "    kfile = tf.io.read_file(file)\n",
    "    key = tf.io.parse_tensor(kfile, out_type=tf.float32)\n",
    "    keyin.append(key)\n",
    "for file in value_file:\n",
    "    vfile = tf.io.read_file(file)\n",
    "    value = tf.io.parse_tensor(vfile, out_type=tf.float32)\n",
    "    valuein.append(value)\n",
    "queryin = tf.stack(queryin)\n",
    "keyin = tf.stack(keyin)\n",
    "valuein = tf.stack(valuein)\n",
    "print(\"Files Successfully Loaded!\")\n",
    "\n",
    "# Set up the parameters\n",
    "batch = 1\n",
    "head = 1\n",
    "length = -1\n",
    "\n",
    "fileidx = np.random.randint(FILENUM)\n",
    "batchidx = np.random.randint(BATCHSIZE)\n",
    "query = queryin[fileidx][batchidx, :, :, :]\n",
    "key = keyin[fileidx][batchidx, :, :, :]\n",
    "value = valuein[fileidx][batchidx, :, :, :]\n",
    "\n",
    "# Generate start matrix with shape 1 * 256 * 16 * 64\n",
    "# Randomly pick a file number\n",
    "for i in range(256 // 64 - 1):\n",
    "  fileidx = np.random.randint(FILENUM)\n",
    "  batchidx = np.random.randint(BATCHSIZE)\n",
    "  query = tf.concat((query, queryin[fileidx][batchidx, :, :, :]), axis=0)\n",
    "  key = tf.concat((key, keyin[fileidx][batchidx, :, :, :]), axis=0)\n",
    "  value = tf.concat((value, valuein[fileidx][batchidx, :, :, :]), axis=0)\n",
    "\n",
    "for idx in range(256 // 64, 8 * 1024 // 64, 1):\n",
    "  start_time = time.time()\n",
    "  peakOld, currOld, peakCurr, currCurr, stoptime = FlatDataflow(idx-256//64, query, key, value, BIAS, batch_granularity_level=batch, \n",
    "                                                      head_granularity_level=head, length_granularity_level=length, headTrue = True)\n",
    "  running_time.append(stoptime - start_time)\n",
    "  fileidx = np.random.randint(FILENUM)\n",
    "  batchidx = np.random.randint(BATCHSIZE)\n",
    "\n",
    "  query = tf.concat((query, queryin[fileidx][batchidx, :, :, :]), axis=0)\n",
    "  key = tf.concat((key, keyin[fileidx][batchidx, :, :, :]), axis=0)\n",
    "  value = tf.concat((value, valuein[fileidx][batchidx, :, :, :]), axis=0)\n",
    "  print(\"LOOP %d\" % (idx) )\n",
    "\n",
    "print(\"Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31d34e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.12507200241088867,\n",
       " 0.04843282699584961,\n",
       " 0.058074951171875,\n",
       " 0.06334114074707031,\n",
       " 0.06549930572509766,\n",
       " 0.07078385353088379,\n",
       " 0.07886791229248047,\n",
       " 0.08131289482116699,\n",
       " 0.09952092170715332,\n",
       " 0.10601091384887695,\n",
       " 0.12760496139526367,\n",
       " 0.14111065864562988,\n",
       " 0.15697979927062988,\n",
       " 0.16658425331115723,\n",
       " 0.21337080001831055,\n",
       " 0.24250292778015137,\n",
       " 0.25846290588378906,\n",
       " 0.28644609451293945,\n",
       " 0.31878232955932617,\n",
       " 0.3431839942932129,\n",
       " 0.3785891532897949,\n",
       " 0.40302276611328125,\n",
       " 0.478057861328125,\n",
       " 0.5046799182891846,\n",
       " 0.46741318702697754,\n",
       " 0.5038840770721436,\n",
       " 0.5495600700378418,\n",
       " 0.5925040245056152,\n",
       " 0.7093391418457031,\n",
       " 0.7467348575592041,\n",
       " 0.7971432209014893,\n",
       " 0.981464147567749,\n",
       " 0.8937628269195557,\n",
       " 0.8569889068603516,\n",
       " 0.9147021770477295,\n",
       " 0.9575960636138916,\n",
       " 1.0245511531829834,\n",
       " 1.0661780834197998,\n",
       " 1.0868008136749268,\n",
       " 1.2870101928710938,\n",
       " 1.3939650058746338,\n",
       " 1.505539894104004,\n",
       " 1.5384180545806885,\n",
       " 1.6107709407806396,\n",
       " 1.730478286743164,\n",
       " 1.7697160243988037,\n",
       " 1.7710950374603271,\n",
       " 1.982752799987793,\n",
       " 1.9818470478057861,\n",
       " 2.1334588527679443,\n",
       " 2.1755259037017822,\n",
       " 2.0075488090515137,\n",
       " 2.1399309635162354,\n",
       " 2.1215500831604004,\n",
       " 2.271162748336792,\n",
       " 2.3411898612976074,\n",
       " 2.338747024536133,\n",
       " 2.5116307735443115,\n",
       " 2.512237787246704,\n",
       " 2.656259059906006,\n",
       " 3.101303815841675,\n",
       " 3.118561029434204,\n",
       " 3.229767084121704,\n",
       " 3.335190773010254,\n",
       " 3.523648977279663,\n",
       " 3.549996852874756,\n",
       " 3.7622690200805664,\n",
       " 3.7989649772644043,\n",
       " 4.130230188369751,\n",
       " 4.221019268035889,\n",
       " 4.271232843399048,\n",
       " 4.419544696807861,\n",
       " 4.499168634414673,\n",
       " 4.66283917427063,\n",
       " 4.5311150550842285,\n",
       " 4.757292032241821,\n",
       " 5.1843438148498535,\n",
       " 5.465312957763672,\n",
       " 5.771845102310181,\n",
       " 5.487228870391846,\n",
       " 5.258127927780151,\n",
       " 5.677196025848389,\n",
       " 5.989488840103149,\n",
       " 6.362452030181885,\n",
       " 6.018388032913208,\n",
       " 6.156529903411865,\n",
       " 6.424623250961304,\n",
       " 8.055126905441284,\n",
       " 8.637959003448486,\n",
       " 8.711825847625732,\n",
       " 8.266355991363525,\n",
       " 8.329294919967651,\n",
       " 9.091997146606445,\n",
       " 8.511121034622192,\n",
       " 8.536053657531738,\n",
       " 8.79502010345459,\n",
       " 8.844274997711182,\n",
       " 9.089034795761108,\n",
       " 9.21188998222351,\n",
       " 8.952839136123657,\n",
       " 8.574840068817139,\n",
       " 9.032868146896362,\n",
       " 9.446654081344604,\n",
       " 9.625715970993042,\n",
       " 9.6319899559021,\n",
       " 9.453541040420532,\n",
       " 9.444940090179443,\n",
       " 9.490026950836182,\n",
       " 9.973213195800781,\n",
       " 9.716187953948975,\n",
       " 10.047528982162476,\n",
       " 10.188260078430176,\n",
       " 11.154506921768188,\n",
       " 11.220543146133423,\n",
       " 11.625970840454102,\n",
       " 10.452139854431152,\n",
       " 10.785213947296143,\n",
       " 10.57429814338684,\n",
       " 10.66426420211792,\n",
       " 11.242106199264526,\n",
       " 13.000407695770264,\n",
       " 12.615241050720215,\n",
       " 12.906336784362793,\n",
       " 12.640007972717285]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb61e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
